{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 4\n",
    "lr = 0.01 \n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.7,), (0.7,)),])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print images using MatPlotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape:  (3, 32, 122)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eight seven six   seven\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    print(\"img shape: \", npimg.shape)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some random images\n",
    "detaiter = iter(trainloader)\n",
    "images, labels = next(detaiter)\n",
    "\n",
    "# Show images \n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Network Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel(\n",
      "  (layer1): Linear(in_features=784, out_features=20, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (layer2): Linear(in_features=20, out_features=50, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (layer3): Linear(in_features=50, out_features=20, bias=True)\n",
      "  (out_activation): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# 4 layer classification model\n",
    "class ClassificationModel(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ClassificationModel,self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size,20)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(20, 50)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(50, 20)\n",
    "        self.out_activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.out_activation(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "cmodel = ClassificationModel(28*28)\n",
    "print(cmodel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim \n",
    "\n",
    "# Criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cmodel.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.948667\n",
      "[1,  4000] loss: 2.772358\n",
      "[1,  6000] loss: 2.660576\n",
      "[1,  8000] loss: 2.550366\n",
      "[1, 10000] loss: 2.513792\n",
      "[1, 12000] loss: 2.511102\n",
      "[1, 14000] loss: 2.503191\n",
      "[2,  2000] loss: 2.496682\n",
      "[2,  4000] loss: 2.501625\n",
      "[2,  6000] loss: 2.475843\n",
      "[2,  8000] loss: 2.410324\n",
      "[2, 10000] loss: 2.366885\n",
      "[2, 12000] loss: 2.370235\n",
      "[2, 14000] loss: 2.359010\n",
      "[3,  2000] loss: 2.354137\n",
      "[3,  4000] loss: 2.332966\n",
      "[3,  6000] loss: 2.302412\n",
      "[3,  8000] loss: 2.298851\n",
      "[3, 10000] loss: 2.283532\n",
      "[3, 12000] loss: 2.290506\n",
      "[3, 14000] loss: 2.280816\n",
      "[4,  2000] loss: 2.271519\n",
      "[4,  4000] loss: 2.266380\n",
      "[4,  6000] loss: 2.272281\n",
      "[4,  8000] loss: 2.278057\n",
      "[4, 10000] loss: 2.273097\n",
      "[4, 12000] loss: 2.280013\n",
      "[4, 14000] loss: 2.269959\n",
      "[5,  2000] loss: 2.259684\n",
      "[5,  4000] loss: 2.265862\n",
      "[5,  6000] loss: 2.260670\n",
      "[5,  8000] loss: 2.271211\n",
      "[5, 10000] loss: 2.262948\n",
      "[5, 12000] loss: 2.261801\n",
      "[5, 14000] loss: 2.258639\n",
      "[6,  2000] loss: 2.256191\n",
      "[6,  4000] loss: 2.261225\n",
      "[6,  6000] loss: 2.259231\n",
      "[6,  8000] loss: 2.259312\n",
      "[6, 10000] loss: 2.254220\n",
      "[6, 12000] loss: 2.256572\n",
      "[6, 14000] loss: 2.260680\n",
      "[7,  2000] loss: 2.255827\n",
      "[7,  4000] loss: 2.262234\n",
      "[7,  6000] loss: 2.243633\n",
      "[7,  8000] loss: 2.255998\n",
      "[7, 10000] loss: 2.253829\n",
      "[7, 12000] loss: 2.250398\n",
      "[7, 14000] loss: 2.250032\n",
      "[8,  2000] loss: 2.249783\n",
      "[8,  4000] loss: 2.261479\n",
      "[8,  6000] loss: 2.247324\n",
      "[8,  8000] loss: 2.251029\n",
      "[8, 10000] loss: 2.249542\n",
      "[8, 12000] loss: 2.249409\n",
      "[8, 14000] loss: 2.249000\n",
      "[9,  2000] loss: 2.240757\n",
      "[9,  4000] loss: 2.249813\n",
      "[9,  6000] loss: 2.246330\n",
      "[9,  8000] loss: 2.246698\n",
      "[9, 10000] loss: 2.245569\n",
      "[9, 12000] loss: 2.244958\n",
      "[9, 14000] loss: 2.244193\n",
      "[10,  2000] loss: 2.243027\n",
      "[10,  4000] loss: 2.249539\n",
      "[10,  6000] loss: 2.240769\n",
      "[10,  8000] loss: 2.242071\n",
      "[10, 10000] loss: 2.242555\n",
      "[10, 12000] loss: 2.240419\n",
      "[10, 14000] loss: 2.244607\n",
      "[11,  2000] loss: 2.230244\n",
      "[11,  4000] loss: 2.241267\n",
      "[11,  6000] loss: 2.242338\n",
      "[11,  8000] loss: 2.242050\n",
      "[11, 10000] loss: 2.240742\n",
      "[11, 12000] loss: 2.248178\n",
      "[11, 14000] loss: 2.234020\n",
      "[12,  2000] loss: 2.238972\n",
      "[12,  4000] loss: 2.233373\n",
      "[12,  6000] loss: 2.241496\n",
      "[12,  8000] loss: 2.232667\n",
      "[12, 10000] loss: 2.236628\n",
      "[12, 12000] loss: 2.238030\n",
      "[12, 14000] loss: 2.239235\n",
      "[13,  2000] loss: 2.233398\n",
      "[13,  4000] loss: 2.241443\n",
      "[13,  6000] loss: 2.237993\n",
      "[13,  8000] loss: 2.235278\n",
      "[13, 10000] loss: 2.235191\n",
      "[13, 12000] loss: 2.235526\n",
      "[13, 14000] loss: 2.233061\n",
      "[14,  2000] loss: 2.228343\n",
      "[14,  4000] loss: 2.229231\n",
      "[14,  6000] loss: 2.240897\n",
      "[14,  8000] loss: 2.238960\n",
      "[14, 10000] loss: 2.238493\n",
      "[14, 12000] loss: 2.237060\n",
      "[14, 14000] loss: 2.227524\n",
      "[15,  2000] loss: 2.225782\n",
      "[15,  4000] loss: 2.234147\n",
      "[15,  6000] loss: 2.231840\n",
      "[15,  8000] loss: 2.228449\n",
      "[15, 10000] loss: 2.229858\n",
      "[15, 12000] loss: 2.233785\n",
      "[15, 14000] loss: 2.234507\n",
      "[16,  2000] loss: 2.233316\n",
      "[16,  4000] loss: 2.230536\n",
      "[16,  6000] loss: 2.229399\n",
      "[16,  8000] loss: 2.229116\n",
      "[16, 10000] loss: 2.226655\n",
      "[16, 12000] loss: 2.230041\n",
      "[16, 14000] loss: 2.228288\n",
      "[17,  2000] loss: 2.228247\n",
      "[17,  4000] loss: 2.222539\n",
      "[17,  6000] loss: 2.234196\n",
      "[17,  8000] loss: 2.228918\n",
      "[17, 10000] loss: 2.223220\n",
      "[17, 12000] loss: 2.229178\n",
      "[17, 14000] loss: 2.230204\n",
      "[18,  2000] loss: 2.221657\n",
      "[18,  4000] loss: 2.225223\n",
      "[18,  6000] loss: 2.226956\n",
      "[18,  8000] loss: 2.233575\n",
      "[18, 10000] loss: 2.228400\n",
      "[18, 12000] loss: 2.222726\n",
      "[18, 14000] loss: 2.232162\n",
      "[19,  2000] loss: 2.226734\n",
      "[19,  4000] loss: 2.224471\n",
      "[19,  6000] loss: 2.231264\n",
      "[19,  8000] loss: 2.236579\n",
      "[19, 10000] loss: 2.228430\n",
      "[19, 12000] loss: 2.220425\n",
      "[19, 14000] loss: 2.222751\n",
      "[20,  2000] loss: 2.221203\n",
      "[20,  4000] loss: 2.228673\n",
      "[20,  6000] loss: 2.224659\n",
      "[20,  8000] loss: 2.235056\n",
      "[20, 10000] loss: 2.225841\n",
      "[20, 12000] loss: 2.220569\n",
      "[20, 14000] loss: 2.229395\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images, labels = data\n",
    "\n",
    "        optimizer.zero_grad()   \n",
    "\n",
    "        outputs = cmodel(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[{epoch+1}, {i + 1:5d}] loss: {running_loss / 2000:3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 60,000 test images: 85 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = cmodel(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 60,000 test images: {100*correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel2(\n",
      "  (layer1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (layer2): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (layer3): Linear(in_features=20, out_features=30, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (layer4): Linear(in_features=30, out_features=20, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (layer5): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (out_activation): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# 6 layer classification model\n",
    "class ClassificationModel2(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ClassificationModel2,self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size,10)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(10, 20)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(20, 30)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.layer4 = nn.Linear(30, 20)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.layer5 = nn.Linear(20, 10)\n",
    "        self.out_activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.out_activation(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "cmodel2 = ClassificationModel2(28*28)\n",
    "optimizer = torch.optim.SGD(cmodel2.parameters(), lr = lr)\n",
    "print(cmodel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.302103\n",
      "[1,  4000] loss: 2.301287\n",
      "[1,  6000] loss: 2.298385\n",
      "[1,  8000] loss: 2.275297\n",
      "[1, 10000] loss: 2.164395\n",
      "[1, 12000] loss: 2.058110\n",
      "[1, 14000] loss: 1.969003\n",
      "[2,  2000] loss: 1.861980\n",
      "[2,  4000] loss: 1.820864\n",
      "[2,  6000] loss: 1.784868\n",
      "[2,  8000] loss: 1.768479\n",
      "[2, 10000] loss: 1.761609\n",
      "[2, 12000] loss: 1.753166\n",
      "[2, 14000] loss: 1.754285\n",
      "[3,  2000] loss: 1.734358\n",
      "[3,  4000] loss: 1.750358\n",
      "[3,  6000] loss: 1.742483\n",
      "[3,  8000] loss: 1.733402\n",
      "[3, 10000] loss: 1.739997\n",
      "[3, 12000] loss: 1.735807\n",
      "[3, 14000] loss: 1.737980\n",
      "[4,  2000] loss: 1.738628\n",
      "[4,  4000] loss: 1.732097\n",
      "[4,  6000] loss: 1.738003\n",
      "[4,  8000] loss: 1.723495\n",
      "[4, 10000] loss: 1.732621\n",
      "[4, 12000] loss: 1.734967\n",
      "[4, 14000] loss: 1.721527\n",
      "[5,  2000] loss: 1.729520\n",
      "[5,  4000] loss: 1.729660\n",
      "[5,  6000] loss: 1.731913\n",
      "[5,  8000] loss: 1.722504\n",
      "[5, 10000] loss: 1.722176\n",
      "[5, 12000] loss: 1.715570\n",
      "[5, 14000] loss: 1.728440\n",
      "[6,  2000] loss: 1.723085\n",
      "[6,  4000] loss: 1.725714\n",
      "[6,  6000] loss: 1.719734\n",
      "[6,  8000] loss: 1.727992\n",
      "[6, 10000] loss: 1.722198\n",
      "[6, 12000] loss: 1.724684\n",
      "[6, 14000] loss: 1.711562\n",
      "[7,  2000] loss: 1.723671\n",
      "[7,  4000] loss: 1.719669\n",
      "[7,  6000] loss: 1.717272\n",
      "[7,  8000] loss: 1.718153\n",
      "[7, 10000] loss: 1.715512\n",
      "[7, 12000] loss: 1.710568\n",
      "[7, 14000] loss: 1.706400\n",
      "[8,  2000] loss: 1.710798\n",
      "[8,  4000] loss: 1.723506\n",
      "[8,  6000] loss: 1.717976\n",
      "[8,  8000] loss: 1.715208\n",
      "[8, 10000] loss: 1.718222\n",
      "[8, 12000] loss: 1.720559\n",
      "[8, 14000] loss: 1.721053\n",
      "[9,  2000] loss: 1.722218\n",
      "[9,  4000] loss: 1.713766\n",
      "[9,  6000] loss: 1.707027\n",
      "[9,  8000] loss: 1.708605\n",
      "[9, 10000] loss: 1.711238\n",
      "[9, 12000] loss: 1.716348\n",
      "[9, 14000] loss: 1.706090\n",
      "[10,  2000] loss: 1.711455\n",
      "[10,  4000] loss: 1.704251\n",
      "[10,  6000] loss: 1.707371\n",
      "[10,  8000] loss: 1.712872\n",
      "[10, 10000] loss: 1.715414\n",
      "[10, 12000] loss: 1.706286\n",
      "[10, 14000] loss: 1.718189\n",
      "[11,  2000] loss: 1.717937\n",
      "[11,  4000] loss: 1.713142\n",
      "[11,  6000] loss: 1.702467\n",
      "[11,  8000] loss: 1.708168\n",
      "[11, 10000] loss: 1.703205\n",
      "[11, 12000] loss: 1.717664\n",
      "[11, 14000] loss: 1.719276\n",
      "[12,  2000] loss: 1.705931\n",
      "[12,  4000] loss: 1.702165\n",
      "[12,  6000] loss: 1.712909\n",
      "[12,  8000] loss: 1.705545\n",
      "[12, 10000] loss: 1.708300\n",
      "[12, 12000] loss: 1.705272\n",
      "[12, 14000] loss: 1.697492\n",
      "[13,  2000] loss: 1.650063\n",
      "[13,  4000] loss: 1.651932\n",
      "[13,  6000] loss: 1.654403\n",
      "[13,  8000] loss: 1.648315\n",
      "[13, 10000] loss: 1.646333\n",
      "[13, 12000] loss: 1.642881\n",
      "[13, 14000] loss: 1.636824\n",
      "[14,  2000] loss: 1.639398\n",
      "[14,  4000] loss: 1.641083\n",
      "[14,  6000] loss: 1.645258\n",
      "[14,  8000] loss: 1.633619\n",
      "[14, 10000] loss: 1.627150\n",
      "[14, 12000] loss: 1.643417\n",
      "[14, 14000] loss: 1.640206\n",
      "[15,  2000] loss: 1.647952\n",
      "[15,  4000] loss: 1.639376\n",
      "[15,  6000] loss: 1.642476\n",
      "[15,  8000] loss: 1.639252\n",
      "[15, 10000] loss: 1.633642\n",
      "[15, 12000] loss: 1.638448\n",
      "[15, 14000] loss: 1.640687\n",
      "[16,  2000] loss: 1.640062\n",
      "[16,  4000] loss: 1.631020\n",
      "[16,  6000] loss: 1.632053\n",
      "[16,  8000] loss: 1.642811\n",
      "[16, 10000] loss: 1.625101\n",
      "[16, 12000] loss: 1.634790\n",
      "[16, 14000] loss: 1.639906\n",
      "[17,  2000] loss: 1.642865\n",
      "[17,  4000] loss: 1.631049\n",
      "[17,  6000] loss: 1.646180\n",
      "[17,  8000] loss: 1.638308\n",
      "[17, 10000] loss: 1.637602\n",
      "[17, 12000] loss: 1.633544\n",
      "[17, 14000] loss: 1.628823\n",
      "[18,  2000] loss: 1.644401\n",
      "[18,  4000] loss: 1.639871\n",
      "[18,  6000] loss: 1.625289\n",
      "[18,  8000] loss: 1.644393\n",
      "[18, 10000] loss: 1.628086\n",
      "[18, 12000] loss: 1.642448\n",
      "[18, 14000] loss: 1.639347\n",
      "[19,  2000] loss: 1.633878\n",
      "[19,  4000] loss: 1.634324\n",
      "[19,  6000] loss: 1.643411\n",
      "[19,  8000] loss: 1.637291\n",
      "[19, 10000] loss: 1.634569\n",
      "[19, 12000] loss: 1.635909\n",
      "[19, 14000] loss: 1.641353\n",
      "[20,  2000] loss: 1.633249\n",
      "[20,  4000] loss: 1.629709\n",
      "[20,  6000] loss: 1.634442\n",
      "[20,  8000] loss: 1.634790\n",
      "[20, 10000] loss: 1.632780\n",
      "[20, 12000] loss: 1.650787\n",
      "[20, 14000] loss: 1.644813\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images, labels = data\n",
    "\n",
    "        optimizer.zero_grad()   \n",
    "\n",
    "        outputs = cmodel2(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[{epoch+1}, {i + 1:5d}] loss: {running_loss / 2000:3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 60,000 test images: 83 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = cmodel2(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 60,000 test images: {100*correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationModel3(\n",
      "  (layer1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (layer2): Linear(in_features=10, out_features=40, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (layer3): Linear(in_features=40, out_features=70, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (layer4): Linear(in_features=70, out_features=40, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (layer5): Linear(in_features=40, out_features=10, bias=True)\n",
      "  (out_activation): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# 6 layer classification model\n",
    "class ClassificationModel3(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ClassificationModel3,self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size,10)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(10, 40)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(40, 70)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.layer4 = nn.Linear(70, 40)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.layer5 = nn.Linear(40, 10)\n",
    "        self.out_activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.out_activation(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "cmodel3 = ClassificationModel3(28*28)\n",
    "optimizer = torch.optim.SGD(cmodel3.parameters(), lr = lr)\n",
    "print(cmodel3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.302390\n",
      "[1,  4000] loss: 2.301673\n",
      "[1,  6000] loss: 2.299902\n",
      "[1,  8000] loss: 2.270108\n",
      "[1, 10000] loss: 2.193524\n",
      "[1, 12000] loss: 2.071415\n",
      "[1, 14000] loss: 1.940704\n",
      "[2,  2000] loss: 1.859803\n",
      "[2,  4000] loss: 1.838214\n",
      "[2,  6000] loss: 1.829606\n",
      "[2,  8000] loss: 1.809322\n",
      "[2, 10000] loss: 1.822718\n",
      "[2, 12000] loss: 1.816866\n",
      "[2, 14000] loss: 1.798883\n",
      "[3,  2000] loss: 1.803777\n",
      "[3,  4000] loss: 1.798094\n",
      "[3,  6000] loss: 1.795883\n",
      "[3,  8000] loss: 1.795840\n",
      "[3, 10000] loss: 1.789050\n",
      "[3, 12000] loss: 1.757133\n",
      "[3, 14000] loss: 1.743102\n",
      "[4,  2000] loss: 1.736533\n",
      "[4,  4000] loss: 1.725802\n",
      "[4,  6000] loss: 1.729669\n",
      "[4,  8000] loss: 1.730535\n",
      "[4, 10000] loss: 1.720577\n",
      "[4, 12000] loss: 1.720831\n",
      "[4, 14000] loss: 1.714643\n",
      "[5,  2000] loss: 1.722208\n",
      "[5,  4000] loss: 1.719739\n",
      "[5,  6000] loss: 1.717218\n",
      "[5,  8000] loss: 1.726192\n",
      "[5, 10000] loss: 1.709545\n",
      "[5, 12000] loss: 1.713187\n",
      "[5, 14000] loss: 1.717785\n",
      "[6,  2000] loss: 1.717777\n",
      "[6,  4000] loss: 1.715523\n",
      "[6,  6000] loss: 1.721765\n",
      "[6,  8000] loss: 1.712225\n",
      "[6, 10000] loss: 1.709673\n",
      "[6, 12000] loss: 1.714886\n",
      "[6, 14000] loss: 1.708021\n",
      "[7,  2000] loss: 1.714498\n",
      "[7,  4000] loss: 1.703288\n",
      "[7,  6000] loss: 1.715103\n",
      "[7,  8000] loss: 1.710947\n",
      "[7, 10000] loss: 1.711315\n",
      "[7, 12000] loss: 1.721835\n",
      "[7, 14000] loss: 1.710118\n",
      "[8,  2000] loss: 1.706466\n",
      "[8,  4000] loss: 1.712506\n",
      "[8,  6000] loss: 1.709250\n",
      "[8,  8000] loss: 1.709657\n",
      "[8, 10000] loss: 1.709118\n",
      "[8, 12000] loss: 1.714862\n",
      "[8, 14000] loss: 1.708181\n",
      "[9,  2000] loss: 1.711840\n",
      "[9,  4000] loss: 1.712847\n",
      "[9,  6000] loss: 1.711339\n",
      "[9,  8000] loss: 1.710389\n",
      "[9, 10000] loss: 1.710749\n",
      "[9, 12000] loss: 1.701217\n",
      "[9, 14000] loss: 1.697681\n",
      "[10,  2000] loss: 1.718150\n",
      "[10,  4000] loss: 1.697287\n",
      "[10,  6000] loss: 1.704771\n",
      "[10,  8000] loss: 1.709308\n",
      "[10, 10000] loss: 1.713947\n",
      "[10, 12000] loss: 1.700947\n",
      "[10, 14000] loss: 1.712178\n",
      "[11,  2000] loss: 1.707029\n",
      "[11,  4000] loss: 1.705361\n",
      "[11,  6000] loss: 1.700663\n",
      "[11,  8000] loss: 1.703757\n",
      "[11, 10000] loss: 1.708670\n",
      "[11, 12000] loss: 1.713596\n",
      "[11, 14000] loss: 1.708297\n",
      "[12,  2000] loss: 1.711971\n",
      "[12,  4000] loss: 1.709814\n",
      "[12,  6000] loss: 1.703559\n",
      "[12,  8000] loss: 1.701687\n",
      "[12, 10000] loss: 1.704972\n",
      "[12, 12000] loss: 1.703571\n",
      "[12, 14000] loss: 1.694533\n",
      "[13,  2000] loss: 1.701103\n",
      "[13,  4000] loss: 1.703222\n",
      "[13,  6000] loss: 1.702294\n",
      "[13,  8000] loss: 1.707701\n",
      "[13, 10000] loss: 1.701198\n",
      "[13, 12000] loss: 1.700008\n",
      "[13, 14000] loss: 1.706651\n",
      "[14,  2000] loss: 1.700967\n",
      "[14,  4000] loss: 1.705328\n",
      "[14,  6000] loss: 1.696679\n",
      "[14,  8000] loss: 1.704272\n",
      "[14, 10000] loss: 1.704789\n",
      "[14, 12000] loss: 1.704914\n",
      "[14, 14000] loss: 1.695081\n",
      "[15,  2000] loss: 1.704378\n",
      "[15,  4000] loss: 1.692837\n",
      "[15,  6000] loss: 1.701171\n",
      "[15,  8000] loss: 1.698780\n",
      "[15, 10000] loss: 1.712131\n",
      "[15, 12000] loss: 1.696776\n",
      "[15, 14000] loss: 1.708659\n",
      "[16,  2000] loss: 1.697272\n",
      "[16,  4000] loss: 1.702644\n",
      "[16,  6000] loss: 1.704293\n",
      "[16,  8000] loss: 1.695227\n",
      "[16, 10000] loss: 1.699669\n",
      "[16, 12000] loss: 1.703622\n",
      "[16, 14000] loss: 1.707163\n",
      "[17,  2000] loss: 1.704284\n",
      "[17,  4000] loss: 1.695211\n",
      "[17,  6000] loss: 1.703486\n",
      "[17,  8000] loss: 1.704411\n",
      "[17, 10000] loss: 1.702443\n",
      "[17, 12000] loss: 1.705720\n",
      "[17, 14000] loss: 1.694184\n",
      "[18,  2000] loss: 1.697581\n",
      "[18,  4000] loss: 1.695737\n",
      "[18,  6000] loss: 1.708331\n",
      "[18,  8000] loss: 1.709004\n",
      "[18, 10000] loss: 1.704421\n",
      "[18, 12000] loss: 1.698884\n",
      "[18, 14000] loss: 1.700651\n",
      "[19,  2000] loss: 1.701706\n",
      "[19,  4000] loss: 1.700172\n",
      "[19,  6000] loss: 1.696175\n",
      "[19,  8000] loss: 1.699466\n",
      "[19, 10000] loss: 1.690607\n",
      "[19, 12000] loss: 1.705334\n",
      "[19, 14000] loss: 1.708009\n",
      "[20,  2000] loss: 1.697807\n",
      "[20,  4000] loss: 1.693625\n",
      "[20,  6000] loss: 1.695306\n",
      "[20,  8000] loss: 1.701347\n",
      "[20, 10000] loss: 1.701573\n",
      "[20, 12000] loss: 1.703979\n",
      "[20, 14000] loss: 1.705491\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images, labels = data\n",
    "\n",
    "        optimizer.zero_grad()   \n",
    "\n",
    "        outputs = cmodel3(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[{epoch+1}, {i + 1:5d}] loss: {running_loss / 2000:3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 60,000 test images: 76 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = cmodel3(images)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 60,000 test images: {100*correct // total} %')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the three models had the least amount of error for validation? \n",
    "The 4 layered model is the one that had the least amount of error for validation with an accuracy percentage of 85%. it is followed by the first 6 layered model with the average accuracy percentage of 83%. Lastly, we have the second 6 layered model with the average accuracy percentage of 76%.\n",
    "\n",
    "How long it took to train each model?\n",
    "    a. The 4 layer model took around 10 minutes to train. \n",
    "    b. The first 6 layer model took around 11 minutes to train\n",
    "    c. The second 6 layer model took around 12 minutes to train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eef1e96883d221b10cc8565d34f43936e0ec43919084d9673b5622bba3d2f1aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
